{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from typing import List, Tuple, Callable\n",
    "from notes import note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(a: np.array, threshold: float, both: bool = True) -> np.array:\n",
    "    max = np.max(a)\n",
    "    a = a / max\n",
    "    a = np.where(a < threshold, a, threshold)\n",
    "    if both:\n",
    "        a = np.where(a > -threshold, a, -threshold)\n",
    "    clipped = a * max\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay(a: np.array, amount: int) -> np.array:\n",
    "    return a + 0.5* np.concatenate([np.zeros(amount), a])[:-amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a: np.array) -> np.array:\n",
    "    return a / np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal(frequency: float, function: Callable = np.sin, part: float = 1, samplerate: int = 44100) -> np.array:\n",
    "    n = samplerate\n",
    "    t = np.linspace(0, 1, samplerate)\n",
    "    wave = function(t*2*np.pi*frequency)\n",
    "    return wave[:int(n*part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord(notes: List[str], function: Callable = np.sin, part: float = 1, samplerate: int = 44100) -> np.array:\n",
    "    n = samplerate\n",
    "    wave = np.zeros(samplerate)\n",
    "    for note_name in notes:\n",
    "        wave = wave + get_signal(note[note_name], function)\n",
    "    return normalize(wave)[:int(n*part)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melody(notes: List[Tuple[str, float]], function: Callable = np.sin, samplerate: int = 44100) -> np.array:\n",
    "    \"\"\"The notes should be a list of tuples. If only a single note (str) is found, it is converted to (str, 1).\"\"\"\n",
    "    convert = lambda n: (n, 1) if type(n) == str else n\n",
    "    notes = [convert(n) for n in notes]\n",
    "    melody = np.concatenate([get_signal(note[n], part=p) for n, p in notes])\n",
    "    return melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(a: np.array, samplerate: int = 44100, volume: float = 0.2, repeat: int = 1):\n",
    "    wave = np.tile(normalize(a)*volume, repeat)\n",
    "    return ipd.Audio(wave, rate=samplerate, autoplay=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chord([\"C2\", \"E4\", \"G4\"])\n",
    "am = chord([\"C2\", \"A3\",  \"E4\"])\n",
    "f = chord([\"F3\", \"A4\", \"C4\"])\n",
    "g = chord([\"G3\", \"B4\", \"D4\"])\n",
    "left = np.concatenate([c, am, f, g])\n",
    "\n",
    "c  = chord([\"C2\"], signal.square)*0.3 + 0*chord([\"C2\"], signal.square) + chord([\"C2\"])\n",
    "am = chord([\"E2\"], signal.square)*0.3 + 0*chord([\"E2\"], signal.square) + chord([\"E2\"])\n",
    "f  = chord([\"F2\"], signal.square)*0.3 + 0*chord([\"F2\"], signal.square) + chord([\"F2\"])\n",
    "g  = chord([\"D2\"], signal.square)*0.3 + 0*chord([\"D2\"], signal.square) + chord([\"D2\"])\n",
    "right = np.concatenate([c, am, f, g]) * 0.4\n",
    "\n",
    "left, right = (left*0.9 + right*0.2), (left*0.1 + right*0.5)\n",
    "left, right = clip(left, 0.3)*0.5 + left*0.3, 0.5*right + clip(right, 0.1) * 0.5\n",
    "\n",
    "song = np.c_[left, right]\n",
    "# song = np.concatenate([song, clip(song, 0.9), clip(song, 0.8), clip(song, 0.7), clip(song, 0.6), clip(song, 0.5), clip(song, 0.4), clip(song, 0.3), clip(song, 0.2), clip(song, 0.1), clip(song, 0.05)])\n",
    "fig, axs = plt.subplots(2, 1, figsize=(64,16))\n",
    "plt.ylim((-1, 1))\n",
    "axs[0].plot(left)\n",
    "axs[1].plot(right)\n",
    "play([left, right], repeat=6, volume=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = np.sum(right)\n",
    "clipped = clip(right, 0.1)\n",
    "vol2 = np.sum(clipped)\n",
    "print(vol1, vol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav(\"out/song.wav\", song.T, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooth = signal.sawtooth(np.linspace(0, 2*np.pi, 1000))\n",
    "clipped = clip(tooth, 0.1, both=True)\n",
    "plt.plot(clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stranger Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = chord([\"C2\"], part=0.3)\n",
    "e2 = chord([\"E2\"], part=0.3)\n",
    "g2 = chord([\"G2\"], part=0.3)\n",
    "b2 = chord([\"B2\"], part=0.3)\n",
    "c3 = chord([\"C3\"], part=0.3)\n",
    "main_melody = np.concatenate([c2, e2, g2, b2, c3, b2, g2, e2])\n",
    "main_melody = clip(main_melody, 0.9)\n",
    "main_melody = np.tile(main_melody, 10)\n",
    "play(main_melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav(\"out/stranger_things.wav\", main_melody, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairy Tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_bar1 = melody([(\"D5\", 1/4), (\"E5\", 1/8), (\"D5\", 1/8), (\"C5\", 1/4), (\"A4\", 1/4), (\"G4\", 1/4), (\"A4\", 1/8), (\"C5\", 1/8), (\"D5\", 1/4), (\"C5\", 1/4)])\n",
    "m_bar2 = melody([(\"D5\", 1/4), (\"E5\", 1/8), (\"D5\", 1/8), (\"C5\", 1/4), (\"A4\", 1/4), (\"G4\", 1/4), (\"A4\", 1/8), (\"C5\", 1/8), (\"F5\", 1/4), (\"E5\", 1/4)])\n",
    "m_bar3 = melody([(\"F5\", 1/4), (\"E5\", 1/8), (\"D5\", 1/8), (\"E5\", 1/4), (\"D5\", 1/8), (\"C5\", 1/8), (\"A4\", 1/8), (\"C5\", 1/8), (\"D5\", 1/8), (\"C5\", 1/8), (\"F5\", 1/4), (\"E5\", 1/4)])\n",
    "fairy_melody = np.concatenate([m_bar1, m_bar2, m_bar1, m_bar3])\n",
    "play(fairy_melody)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bar1 = np.concatenate([chord([\"D1\", \"D2\"], part=4/4), chord([\"D1\", \"D2\"], part=4/4)])\n",
    "b_bar2 = np.concatenate([chord([\"F1\", \"F2\"], part=4/4), chord([\"F1\", \"F2\"], part=4/4)])\n",
    "b_bar3 = np.concatenate([chord([\"C2\", \"C3\"], part=4/4), chord([\"C2\", \"C3\"], part=4/4)]) * 0.6\n",
    "b_bar4 = np.concatenate([chord([\"Bb1\", \"Bb2\"], part=4/4), chord([\"C2\", \"C3\"], part=4/4)]) * 0.6\n",
    "fairy_bass = np.concatenate([b_bar1, b_bar2, b_bar3, b_bar4]) * 2\n",
    "play(fairy_bass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My *ahem* accurate functions sometimes lop of a few elements of the sound array, so I have to equalize the two parts. Since only lopping off occurs, and no additive nonsense, I just have to pad one array a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bass_n = len(fairy_bass)\n",
    "melody_n = len(fairy_melody)\n",
    "print(f\"{bass_n=}, {melody_n=}\")\n",
    "diff = melody_n - bass_n\n",
    "print(diff)\n",
    "if diff < 0: # bass is longer\n",
    "    fairy_melody = np.pad(fairy_melody, (0, np.abs(diff)))\n",
    "elif diff > 0: # melody is longer\n",
    "    fairy_bass = np.pad(fairy_bass, (0, np.abs(diff)))\n",
    "print(fairy_melody.shape, fairy_bass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(fairy_melody + fairy_bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairy_tail = np.tile(normalize(fairy_melody + fairy_bass), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav(\"out/fairy_tail.wav\", fairy_tail, 44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
